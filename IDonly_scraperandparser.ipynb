{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "#!pip install requests beautifulsoup4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "import re\n",
    "import pandas as pd\n",
    "from selenium import webdriver\n",
    "from selenium.webdriver.edge.service import Service as EdgeService\n",
    "from selenium.webdriver.edge.options import Options as EdgeOptions\n",
    "from selenium.webdriver.common.by import By\n",
    "import time\n",
    "import os\n",
    "from selenium import webdriver\n",
    "from datetime import datetime\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fetching page 1...\n",
      "Fetching page 2...\n",
      "Fetching page 3...\n",
      "Fetching page 4...\n",
      "Fetching page 5...\n",
      "Fetching page 6...\n",
      "Fetching page 7...\n",
      "Fetching page 8...\n",
      "Fetching page 9...\n",
      "Fetching page 10...\n",
      "Fetching page 11...\n",
      "Fetching page 12...\n",
      "Fetching page 13...\n",
      "✅ Done! File saved to: c:\\Users\\alons\\OneDrive - Cornell University\\Cornell University\\Spring 2025\\CFEM Research Assistant\\Parser\\royalty_scraper\\royaltyexchange_pages.txt\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# Set up Edge options\n",
    "edge_options = EdgeOptions()\n",
    "edge_options.add_argument(\"headless\")  # Remove this line if you want to see the browser\n",
    "\n",
    "# Path to Edge WebDriver\n",
    "service = EdgeService(r\"C:\\Users\\alons\\Downloads\\Installers\\edgedriver_win64\\msedgedriver.exe\")\n",
    "\n",
    "# Start the WebDriver\n",
    "driver = webdriver.Edge(service=service, options=edge_options)\n",
    "\n",
    "# Base URL template\n",
    "base_url = (\n",
    "    \"https://auctions.royaltyexchange.com/orderbook/open-listings/\"\n",
    "    \"?filter{{state.in}}=open&filter{{state.in}}=upcoming&filter{{state.in}}=preview\"\n",
    "    \"&filter{{state.in}}=listed&filter{{state.in}}=live&only_favorited=0&only_offered=0\"\n",
    "    \"&only_user_active_offers=0&sort[]=-is_open_auction&sort[]=-close_date\"\n",
    "    \"&sort[]=featured_position&sort[]=-if_new_published_date\"\n",
    "    \"&sort[]=-owner_last_active_date&sort[]=-published_date&page={}&page_size=50\"\n",
    ")\n",
    "\n",
    "# Load page 1 to detect number of pages\n",
    "driver.get(base_url.format(1))\n",
    "time.sleep(2)\n",
    "\n",
    "# Detect pagination. This element holds a unordered list with the total number of pages\n",
    "pagination_buttons = driver.find_elements(By.CSS_SELECTOR, \"ul.MuiPagination-ul > li button\")\n",
    "\n",
    "\n",
    "# Determine total number of pages dynamically\n",
    "page_numbers = []\n",
    "for btn in pagination_buttons:\n",
    "    try:\n",
    "        num = int(btn.text)\n",
    "        page_numbers.append(num)\n",
    "    except ValueError:\n",
    "        continue  # ignore non-numeric buttons\n",
    "\n",
    "last_page = max(page_numbers) if page_numbers else 1\n",
    "\n",
    "# Collect pages\n",
    "all_pages_html = \"\"\n",
    "\n",
    "for page_num in range(1, last_page + 1):\n",
    "    print(f\"Fetching page {page_num}...\")\n",
    "    driver.get(base_url.format(page_num))\n",
    "    time.sleep(2)\n",
    "    all_pages_html += driver.page_source + \"\\n\\n\" + \"=\" * 100 + \"\\n\\n\"\n",
    "\n",
    "driver.quit()\n",
    "\n",
    "# Save in the current working directory\n",
    "output_path = os.path.join(os.getcwd(), \"royaltyexchange_pages.txt\")\n",
    "\n",
    "with open(output_path, \"w\", encoding=\"utf-8\") as f:\n",
    "    f.write(all_pages_html)\n",
    "\n",
    "print(f\"✅ Done! File saved to: {output_path}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved to new_extracted_listing_ids_2025-04-05.csv\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# Load content from file\n",
    "with open(\"royaltyexchange_pages.txt\", \"r\", encoding=\"utf-8\") as f:\n",
    "    new_content = f.read()\n",
    "\n",
    "# Extract all numbers that follow \"ID:\"\n",
    "new_ids = re.findall(r'ID:\\s*(\\d+)', new_content)\n",
    "\n",
    "# Create a DataFrame\n",
    "df_new_ids = pd.DataFrame(new_ids, columns=['Listing ID'])\n",
    "\n",
    "# Generate date string\n",
    "today_str = datetime.today().strftime('%Y-%m-%d')\n",
    "\n",
    "# Save to CSV with date\n",
    "filename = f\"new_extracted_listing_ids_{today_str}.csv\"\n",
    "df_new_ids.to_csv(filename, index=False)\n",
    "\n",
    "print(f\"Saved to {filename}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
